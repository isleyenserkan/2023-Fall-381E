{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa681f85-4dee-4b8a-8439-d601ffd93d41",
   "metadata": {},
   "source": [
    "# Homework #4\n",
    "\n",
    "## Overall rules:\n",
    "\n",
    "- Refrain from saving datasets locally. You may experiment with your answers on a locally saved version of the datasets, but do not upload your local files with your homework as the datasets are very large. In your submitted answers datasets should be read from the original source URL.\n",
    "- Document all of your steps by writing appropriate markdown cells in your notebook. Refrain from using code comments to explain what has been done. \n",
    "- Avoid duplicating code. Do not copy and paste code from one cell to another. If copying and pasting is necessary, write a suitable function for the task at hand and call that function.\n",
    "- Document your use of LLM models (ChatGPT, Claude, Code Pilot etc). Either take screenshots of your steps and include them with this notebook, or give me a full log (both questions and answers) in a markdown file named `HW4-LLM-LOG.md`.\n",
    "\n",
    "Failure to adhere to these guidelines will result in a 25-point deduction for each infraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b9ba1-692b-48a9-8a9f-6be0d0ffde21",
   "metadata": {},
   "source": [
    "## Q1 (Author attribution)\n",
    "\n",
    "For this question we are going to use two novels:\n",
    "- [Jayne Eyre](https://www.gutenberg.org/ebooks/1260) by Charlotte Bronte, and\n",
    "- [Pride and Prejudice](https://www.gutenberg.org/ebooks/1342) by Jane Austen.\n",
    "\n",
    "1. Get the novels' plain text versions and remove all the parts which do not belong to the novels.\n",
    "2. Using NLTK's sentence tokenizers, tokenize each novel.\n",
    "3. Label sentences by 0 or 1 depending on whether the sentence is written by Austen or Bronte, and then merge the two sentence data sets.\n",
    "4. Vectorize the merged sentence dataset. (Tell the vectorizer to remove all stop words.)\n",
    "5. Split the vectorized sentences and labels as train and test. Use the 25% of the data as test.\n",
    "6. Train a logistic regression model on the train subset.\n",
    "7. Using the model you trained, predict labels on the test set, and then construct a confusion matrix.\n",
    "8. Can your model distinguish sentences written by Bronte or Austen? Analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174df88-453d-47c3-8f62-9e8f0735ab99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e778131-2eef-4da5-8e44-a19d668f1ba5",
   "metadata": {},
   "source": [
    "## Q2 (Voice recognition)\n",
    "\n",
    "For this question we are going to use the [Axiom voice recognition dataset](https://zenodo.org/records/1218979). The voice data contains data for 73 individuals. Since the dataset is fairly large, do not commit your local copy to github.\n",
    "\n",
    "1. Build machine learning models that distinguish these individuals.\n",
    "2. Test your model(s) and calculate their accuracies.\n",
    "3. Construct and display confusion matrix or matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72acff31-fe37-4798-98c7-a27f84bb6643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6786633f-ee50-4cf1-ad04-33c4eb5a06be",
   "metadata": {},
   "source": [
    "## Q3 (City hopping)\n",
    "\n",
    "For this question we are going to use [Open Flight Data](https://openflights.org/data.php).\n",
    "\n",
    "1. Pull the data on airports and routes. Clean it and put the correct names on columns. Read the [documentation on the data](https://openflights.org/data.php).\n",
    "2. Merge the route dataset and the airport dataset so the combined version has route source and target airports has full airport names and cities instead of airport codes.\n",
    "3. Construct a graph where each node is a city, and two cities are connected by an edge if there is a flight between these cities.\n",
    "4. Find the flight routes with the minimal number of stops for the following source and target cities. For example, a route that has the minimal number of connections/stops from Antalya to Deer Lake (Canada) is Antalya, London, Halifax, Deer Lake.\n",
    "   - From Adana (Turkey) to Auckland (New Zealand)\n",
    "   - From Ankara (Turkey) to Kona (Hawaii, USA)\n",
    "   - From Sydney (Australia) to Churchhill (Canada)\n",
    "5. Using the networkx's implementation of the [Page Rank Algorithm](https://en.wikipedia.org/wiki/PageRank) find the top 10 cities that are important for the global flight network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f159e98-72e1-456f-8e25-852dfe36bf47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "243df65b-3d23-4591-a982-d77809b8cd10",
   "metadata": {},
   "source": [
    "## Q4 ([Six degrees of Kevin Bacon](https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon))\n",
    "\n",
    "For this question we are going to use [IMDB datasets](https://datasets.imdbws.com/). Read the [documentation](https://developer.imdb.com/non-commercial-datasets/) for what each of the dataset is for. Pull the data and merge the appropriate datasets for the followwing tasks. The datasets are fairly large. Do not commit the datasets to the github repo!\n",
    "\n",
    "1. Construct a graph where the nodes are actors and actresses, and two actors/actresses are connected by a weighted edge if these people appeared in the same movie together. The weight of any edge is the number of movies these people appear together. For example Haluk Bilginer and Bekir Aksoy appeared together in 40 movies or TV series episodes.\n",
    "2. Using the graph you constructed find the shortest paths between following pairs of actors/actresses. For example the shortest path between Haluk Bilginer and Kevin Bacon is Haluk Bilginer, Danny Glover, Patricia Clarkson, and Kevin Bacon where any two consecutive actors/actresses appeared together in a movie.\n",
    "   - Charles Chaplin and Nur Sürer\n",
    "   - Paul Newman and Keanu Reeves\n",
    "   - Harold Lloyd and Zoey Kazan\n",
    "   - Vanessa Redgrave and Tilda Swinton\n",
    "3. Using eigen-value centrality, find 10 actors/actresses that are important for the actor/actress network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e865f22-8c6a-4349-8b2b-591e2bcfc147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bcabac2-6926-4732-b409-03a942902e56",
   "metadata": {},
   "source": [
    "## Q5 (Shopping for best universities for math PhD)\n",
    "\n",
    "For this question is about [Math Genealogy](https://genealogy.math.ndsu.nodak.edu/index.php) and we are going to use [the data](https://github.com/j2kun/math-genealogy-scraper) that was already scraped by [Jeremy Kun](https://jeremykun.com/). We don't need the whole repo by Kun, just 'data.json' from the repository. Pull the data and process it accordingly for the tasks below. Again, since the dataset is fairly large do not commit it to your github repo.\n",
    "\n",
    "Data consists of historical data on PhD dissertation. A sample entry would look like as follows:\n",
    "\n",
    "    {\n",
    "      \"id\": 13325,\n",
    "      \"name\": \"Daniel Gray Quillen\",\n",
    "      \"thesis\": \"Formal Properties of Over-Determined Systems of Linear Partial Differential Equations\",\n",
    "      \"school\": \"Harvard University\",\n",
    "      \"country\": \"UnitedStates\",\n",
    "      \"year\": 1964,\n",
    "      \"subject\": \"19—K-theory\",\n",
    "      \"advisors\": [\n",
    "        7583\n",
    "      ],\n",
    "      \"students\": [\n",
    "        62762,\n",
    "        67441,\n",
    "        30219,\n",
    "        62770,\n",
    "        62764,\n",
    "        62771\n",
    "      ]\n",
    "    },\n",
    "\n",
    "The name of the person who wrote the thesis is Daniel Gray Quillen, and his unique id is 13325. His thesis title is \"Formal Properties of Over-Determined Systems of Linear Partial Differential Equations\". He got his PhD degree from Harvard in 1964. His advisor's id is 7583 (Raul Bott). Note that the advisors field is an array since a student might have more than 1 advisor. The student field indicates Quillen had 6 PhD students with those specific id's\n",
    "\n",
    "1. Construct a graph where nodes are countries. Two countries A and B are connected by an edge if a mathematician whose PhD degree awared by a university in A, had a PhD student at a university in the country B, or vice versa. Attach a weight to the edge by counting the number of all such instances. For example, Quillen had his degree from Harvard which is in the US. 5 of his students got their degrees at MIT which is also in the US while the 6th got his degree from Oxford which is in the UK. Thus Quillen adds 5 to the edge (which indeed is a loop) between the US and the US, and 1 to the edge between the US and the UK.\n",
    "2. Using the Page Rank algorithm find the top 10 important countries in mathematics.\n",
    "3. Construct a new graph where nodes are universities with the same rules as above. Again, using the Quillen example above: Quillen adds 5 to the edge between Harvard and MIT, and 1 to the edge between Harvard and Oxford.\n",
    "4. Using the Page Rank algorithm find the top 10 important universities in mathematics.\n",
    "5. Now, write a function that takes the name of a math subject (such as 'K-theory') and returns the top 10 important schools for the university network properly filtered. In other words, this time you will only consider the PhD degrees in the given subject alone. Find out the top 10 universities for the following subjects:\n",
    "   - Statistics\n",
    "   - Group theory\n",
    "   - Topology\n",
    "   - Functional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a675006-3d4a-4eb9-8114-18a44e1cd2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
